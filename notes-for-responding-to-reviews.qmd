---
title: "Automating fisheries modelling with agentic AI"
bibliography: references.bib
editor: source
format: docx
---

## @campbell2024

Campbell provides the graduate student perspective on using AI for learning statistics and coding and overall finds it to be a helpful tool, but notes some limitations. Key limitations include:

1. **Requirement for extensive knowledge to write good prompts**: In my experience, this is true. It's difficult to balance between writing vague prompts (which don't yield good responses from a beginner's perspective) and writing really good prompts (which means you've basically done the work already). There's a middle ground where experts who know what type of statistical analysis they want to do can describe it accurately, and then AI can helpfully do the coding. However, a beginner user wouldn't be able to do this effectively.

2. **Context poisoning**: They didn't call it this, but noted the idea that sometimes AI gives you the wrong answer, and you can't correct the conversation. This is largely known to be true—once you get a chat going in the wrong direction, you're better off starting a new chat than trying to continue with the current one. This is something I should note in my paper.

## @cooper2024

In the editorial, Cooper et al. discuss the opportunities of using AI for ecological modeling and emphasize the importance of transparency around AI use. I found some of this actually unrealistic because AI use becomes so intertwined with how you work that it's difficult to document line by line what's been done by AI versus what's been done by a human.

Cooper et al. address several uses of AI for coding, including:
- Translating code from other languages
- Explaining code
- Helping write unit tests
- Debugging and fixing errors

They also discuss whether we still need to learn and teach coding, concluding that it remains important. They probably understate the current power of AI when they say we still need to learn how to check code, which I increasingly don't think will be true. However, they are right that teaching coding is important for pedagogical reasons—it helps break problems down into smaller parts and encourages logical, reasoned thinking. Without learning those coding skills, it might be harder to think about how to break problems down into component parts.

## @millard2024

Millard addresses loneliness as an issue, noting that ChatGPT is reducing social interactions because people who would have previously gone to colleagues, postdocs, or other students for help with coding now turn to ChatGPT instead. This reduces opportunities for collaboration, human kindness, and support networks. They suggest some ways this could be addressed. I don't think this paper is as relevant to mine, so I probably don't need to cite it.

## @johnson2024

Johnson raises the issue of pressure to publish with AI, which relates to my work. I should cite this when discussing "supercharged p-hacking" because they also discuss hacking entire papers where people can quickly create similar papers repeatedly. This could create a p-hacking situation but with entire papers. When I discuss p-hacking and AI's ability to run many models on the same data and then pick the best one, I should cite their paper.

## Research Plans and Ideas

In terms of my paper, I need to add some content based on reviewer feedback. Reviewers wanted clarification between my own opinions versus what was supported by data, so I need to make this clearer through editing. They also wanted real examples, so I should add simple examples of prompt tests.

### Proposed Examples

One idea is to set up a simple system with the Elmer package and test alternative prompts around one of my four areas of improvement. I could:

1. **Create boxes showing agent coding results**
2. **Conduct unit tests/compartmentalized tests** with simple system prompts and single questions, looking at different formats and analyzing responses
3. **Focus on random effects modeling** as an example that's different enough from my fisheries work
4. **Extract modal responses** for questions about random effects structure recommendations

### Implementation Testing

For the implementation section, I could:
- Compare models' abilities to generate error-free code with simple system prompts
- Test code documentation capabilities
- Conduct simple tests (10 iterations) where models write code and produce output/plots that can be evaluated

I'll include one small example of an agent and focus on different prompting strategies throughout these tests.

### Agent Classification Update

I need to update the section on agents with more information about what agents are. I should replace some background information about how LLMs work and instead include a basic hierarchy:

1. **Basic LLMs** that just respond to questions
2. **Tool-enabled LLMs** where you give the LLM tools
3. **Three broad types of agents**:
   - **File editors**: Simple tools that search patterns in code and edit files
   - **Autonomous computer agents**: Operate autonomously, iterating on tasks, running code, checking results
   - **Internet-connected agents**: Connected to tools and MCP on the internet, opening new security issues but also opportunities

I'll address these three categories in the paper as well.